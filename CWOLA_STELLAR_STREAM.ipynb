{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0c579ab-f3b8-429c-b09a-225f6aa2bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 3 is maximum: Errors Only\n",
    "os.environ['HOROVOD_LOG_LEVEL'] = 'FATAL'  # (optional: if Horovod is used under the hood)\n",
    "os.environ['NCCL_DEBUG'] = 'WARN'  # reduce NCCL verbosity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "# ==== MASTER CONTROL ====\n",
    "PLOT = False  # Set to True if you want plots\n",
    "# =========================\n",
    "\n",
    "# --- Matplotlib Settings ---\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 200,\n",
    "    \"text.usetex\": True,\n",
    "    \"pgf.rcfonts\": False,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.size\": 15,\n",
    "    \"xtick.labelsize\": 11,\n",
    "    \"ytick.labelsize\": 11,\n",
    "    \"legend.fontsize\": 11,\n",
    "    \"figure.max_open_warning\": False,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899ba456-613c-4df6-b6a0-f8be3f32ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(df, save_folder=\"./plots\"): \n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    fig = plt.figure(figsize=(13,8), dpi=200, tight_layout=True)\n",
    "\n",
    "    cmap = 'Greys'\n",
    "    bins_0 = (np.linspace(-15,15,100), np.linspace(-15,15,100))\n",
    "    bins_1 = (np.linspace(-20,10,100), np.linspace(-20,10,100))\n",
    "    bins_2 = (np.linspace(0,3,100), np.linspace(9,20.2,100))\n",
    "\n",
    "    ax = fig.add_subplot(231)\n",
    "    h = ax.hist2d(df['ϕ'], df['λ'], cmap=cmap, cmin=1, vmax=250, bins=bins_0)\n",
    "    ax.set_xlabel(r'$\\phi~[^\\circ]$',fontsize=20)\n",
    "    ax.set_ylabel(r'$\\lambda~[^\\circ]$',fontsize=20)\n",
    "    ax.set_xlim(-15,15)\n",
    "    ax.set_ylim(-15,15)\n",
    "    fig.colorbar(h[3], ax=ax)\n",
    "\n",
    "    ax = fig.add_subplot(232)\n",
    "    h = ax.hist2d(df['μ_ϕcosλ'], df['μ_λ'], cmap=cmap, cmin=1, bins=bins_1)\n",
    "    ax.set_xlim(-20,10)\n",
    "    ax.set_ylim(-20,10)\n",
    "    ax.set_xlabel(r'$\\mu_\\phi^*$ [mas/yr]',fontsize=20)\n",
    "    ax.set_ylabel(r'$\\mu_\\lambda$ [mas/yr]',fontsize=20)\n",
    "    fig.colorbar(h[3], ax=ax)\n",
    "    ax.set_title('Full Patch', fontsize=25, pad=15)\n",
    "\n",
    "    ax = fig.add_subplot(233)\n",
    "    h = ax.hist2d(df['b-r'], df['g'], cmap=cmap, cmin=1, bins=bins_2)\n",
    "    ax.set_xlabel(r'$b-r$',fontsize=20)\n",
    "    ax.set_ylabel(r'$g$',fontsize=20)\n",
    "    ax.set_xlim(0,3)\n",
    "    ax.invert_yaxis()\n",
    "    fig.colorbar(h[3], ax=ax)\n",
    "\n",
    "    ax = fig.add_subplot(234)\n",
    "    h = ax.hist2d(df[df.stream]['ϕ'], df[df.stream]['λ'], cmap='Reds', bins=bins_0, cmin=1)\n",
    "    ax.set_xlabel(r'$\\phi~[^\\circ]$',fontsize=20)\n",
    "    ax.set_ylabel(r'$\\lambda~[^\\circ]$',fontsize=20)\n",
    "    ax.set_xlim(-15,15)\n",
    "    ax.set_ylim(-15,15)\n",
    "    fig.colorbar(h[3], ax=ax)\n",
    "\n",
    "    ax = fig.add_subplot(235)\n",
    "    h = ax.hist2d(df[df.stream]['μ_ϕcosλ'], df[df.stream]['μ_λ'], cmap='Reds', cmin=1, bins=bins_1)\n",
    "    ax.set_xlim(-20,10)\n",
    "    ax.set_ylim(-20,10)\n",
    "    ax.set_xlabel(r'$\\mu_\\phi^*$ [mas/yr]',fontsize=20)\n",
    "    ax.set_ylabel(r'$\\mu_\\lambda$ [mas/yr]',fontsize=20)\n",
    "    fig.colorbar(h[3], ax=ax)\n",
    "    ax.set_title('Labeled Stream Stars', fontsize=25, pad=15)\n",
    "\n",
    "    ax = fig.add_subplot(236)\n",
    "    h = ax.hist2d(df[df.stream]['b-r'], df[df.stream]['g'], cmap='Reds', cmin=1, bins=bins_2)\n",
    "    ax.set_xlabel(r'$b-r$',fontsize=20)\n",
    "    ax.set_ylabel(r'$g$',fontsize=20)\n",
    "    ax.set_xlim(0,3)\n",
    "    ax.set_ylim(9,20.2)\n",
    "    ax.invert_yaxis()\n",
    "    fig.colorbar(h[3], ax=ax)\n",
    "\n",
    "    plt.savefig(os.path.join(save_folder, \"coords.pdf\"))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93cdd492-dbf0-4a0b-8108-48aab2b34d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(df, save_folder=\"../plots\", plot=PLOT):\n",
    "    if not plot:\n",
    "        return  # Skip plotting entirely if plot=False\n",
    "\n",
    "    fig = plt.figure(figsize=(13,8), dpi=200, tight_layout=True)\n",
    "\n",
    "    cmap = 'Greys'\n",
    "    bins_0 = (np.linspace(-15,15,100), np.linspace(-15,15,100))\n",
    "    bins_1 = (np.linspace(-20,10,100), np.linspace(-20,10,100))\n",
    "    bins_2 = (np.linspace(0,3,100), np.linspace(9,20.2,100))\n",
    "\n",
    "    ax = fig.add_subplot(231)\n",
    "    h = ax.hist2d(df['ϕ'], df['λ'], cmap=cmap, cmin=1, vmax=250, bins=bins_0)\n",
    "    ax.set_xlabel(r'$\\phi~[^\\circ]$', fontsize=20)\n",
    "    ax.set_ylabel(r'$\\lambda~[^\\circ]$', fontsize=20)\n",
    "    ax.set_xlim(-15,15)\n",
    "    ax.set_ylim(-15,15)\n",
    "    fig.colorbar(h[3], ax=ax)\n",
    "\n",
    "    ax = fig.add_subplot(232)\n",
    "    h = ax.hist2d(df['μ_ϕcosλ'], df['μ_λ'], cmap=cmap, cmin=1, bins=bins_1)\n",
    "    ax.set_xlim(-20,10)\n",
    "    ax.set_ylim(-20,10)\n",
    "    ax.set_xlabel(r'$\\mu_\\phi^*$ [mas/yr]', fontsize=20)\n",
    "    ax.set_ylabel(r'$\\mu_\\lambda$ [mas/yr]', fontsize=20)\n",
    "    fig.colorbar(h[3], ax=ax)\n",
    "    ax.set_title('Full Patch', fontsize=25, pad=15)\n",
    "\n",
    "    ax = fig.add_subplot(233)\n",
    "    h = ax.hist2d(df['b-r'], df['g'], cmap=cmap, cmin=1, bins=bins_2)\n",
    "    ax.set_xlabel(r'$b-r$', fontsize=20)\n",
    "    ax.set_ylabel(r'$g$', fontsize=20)\n",
    "    ax.set_xlim(0,3)\n",
    "    ax.invert_yaxis()\n",
    "    fig.colorbar(h[3], ax=ax)\n",
    "\n",
    "    ax = fig.add_subplot(234)\n",
    "    h = ax.hist2d(df[df.stream]['ϕ'], df[df.stream]['λ'], cmap='Reds', bins=bins_0, cmin=1)\n",
    "    ax.set_xlabel(r'$\\phi~[^\\circ]$', fontsize=20)\n",
    "    ax.set_ylabel(r'$\\lambda~[^\\circ]$', fontsize=20)\n",
    "    ax.set_xlim(-15,15)\n",
    "    ax.set_ylim(-15,15)\n",
    "    fig.colorbar(h[3], ax=ax)\n",
    "\n",
    "    ax = fig.add_subplot(235)\n",
    "    h = ax.hist2d(df[df.stream]['μ_ϕcosλ'], df[df.stream]['μ_λ'], cmap='Reds', cmin=1, bins=bins_1)\n",
    "    ax.set_xlim(-20,10)\n",
    "    ax.set_ylim(-20,10)\n",
    "    ax.set_xlabel(r'$\\mu_\\phi^*$ [mas/yr]', fontsize=20)\n",
    "    ax.set_ylabel(r'$\\mu_\\lambda$ [mas/yr]', fontsize=20)\n",
    "    fig.colorbar(h[3], ax=ax)\n",
    "    ax.set_title('Labeled Stream Stars', fontsize=25, pad=15)\n",
    "\n",
    "    ax = fig.add_subplot(236)\n",
    "    h = ax.hist2d(df[df.stream]['b-r'], df[df.stream]['g'], cmap='Reds', cmin=1, bins=bins_2)\n",
    "    ax.set_xlabel(r'$b-r$', fontsize=20)\n",
    "    ax.set_ylabel(r'$g$', fontsize=20)\n",
    "    ax.set_xlim(0,3)\n",
    "    ax.set_ylim(9,20.2)\n",
    "    ax.invert_yaxis()\n",
    "    fig.colorbar(h[3], ax=ax)\n",
    "\n",
    "    plt.savefig(os.path.join(save_folder, \"coords.pdf\"))\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a975df2-3748-4b26-b6c4-58defb70b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_sideband(df, sr_factor=1, sb_factor=3, save_folder=None, sb_min=None, sb_max=None, sr_min=None, sr_max=None, verbose=True, scan_over_mu_phi=False):\n",
    "    print(\"SR factor:\", sr_factor)\n",
    "    print(\"SB factor:\", sb_factor)\n",
    "\n",
    "    if scan_over_mu_phi:\n",
    "        var = \"μ_ϕcosλ\"\n",
    "    else:\n",
    "        var = \"μ_λ\"\n",
    "        \n",
    "    print(\"Scanning over\", var)\n",
    "\n",
    "    if sb_min is None:\n",
    "        if df[df.stream].empty:\n",
    "            print(\"No stellar streams found. Setting artificial bounds.\")\n",
    "            sb_min = df[var].quantile(0.25)\n",
    "            sb_max = df[var].quantile(0.75)\n",
    "            sr_min = df[var].quantile(0.4)\n",
    "            sr_max = df[var].quantile(0.6)\n",
    "        else:\n",
    "            sb_min = df[df.stream][var].median() - sb_factor * df[df.stream][var].std()\n",
    "            sb_max = df[df.stream][var].median() + sb_factor * df[df.stream][var].std()\n",
    "            sr_min = df[df.stream][var].median() - sr_factor * df[df.stream][var].std()\n",
    "            sr_max = df[df.stream][var].median() + sr_factor * df[df.stream][var].std()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Sideband region: [{sb_min:.1f},{sr_min:.1f}) & ({sr_max:.1f},{sb_max:.1f}]\")\n",
    "        print(f\"Signal region: [{sr_min:.1f},{sr_max:.1f}]\")\n",
    "\n",
    "    df_slice = df[(df[var] >= sb_min) & (df[var] <= sb_max)].copy()\n",
    "    df_slice['label'] = np.where(((df_slice[var] >= sr_min) & (df_slice[var] <= sr_max)), 1, 0)\n",
    "\n",
    "    return df_slice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9de4b84-4d55-41ea-ab77-7c314d07edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(test, top_n=[50, 100], save_folder=None, verbose=True, show=True, plot=PLOT):\n",
    "    if not plot:\n",
    "        return  # <- if plotting is disabled, just exit immediately\n",
    "\n",
    "    if save_folder is not None:\n",
    "        os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, 3), dpi=150, constrained_layout=True)\n",
    "    bins = np.linspace(0, 1, 50)\n",
    "\n",
    "    axs[0].hist(test[test.label == 1].nn_score, bins=bins, histtype='step', linewidth=2, color=\"dodgerblue\", label=\"Signal Region\")\n",
    "    axs[0].hist(test[test.label == 0].nn_score, bins=bins, histtype='step', linewidth=2, color=\"orange\", label=\"Sideband Region\")\n",
    "    axs[0].legend(fontsize=12)\n",
    "    axs[0].set_xlim(0, 1)\n",
    "    axs[0].set_xlabel(\"NN Score\")\n",
    "    axs[0].set_ylabel(\"Events\")\n",
    "    axs[0].set_title(\"Test Set\")\n",
    "\n",
    "    if \"stream\" in test.columns:\n",
    "        axs[1].hist(test[test.stream == False].nn_score, bins=bins, histtype='step', linewidth=2, color=\"grey\", label=\"Not Stream\")\n",
    "        axs[1].hist(test[test.stream == True].nn_score, bins=bins, histtype='step', linewidth=2, color=\"crimson\", label=\"Stream\")\n",
    "        axs[1].set_yscale(\"log\")\n",
    "        axs[1].set_xlim(0, 1)\n",
    "        axs[1].set_xlabel(\"NN Score\")\n",
    "        axs[1].set_ylabel(\"Events\")\n",
    "        axs[1].legend(fontsize=12)\n",
    "\n",
    "    if save_folder:\n",
    "        plt.savefig(os.path.join(save_folder, \"nn_scores.png\"))\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7eaca9-bff5-43bf-9b23-b70a54ae2675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def angular_distance(angle1, angle2):\n",
    "    deltara = np.minimum(np.minimum(np.abs(angle1[:,0] - angle2[:,0] + 360), np.abs(angle1[:,0] - angle2[:,0])), np.abs(angle1[:,0] - angle2[:,0] - 360))\n",
    "    deltadec = np.abs(angle1[:,1] - angle2[:,1])\n",
    "    return np.sqrt(deltara**2 + deltadec**2)\n",
    "\n",
    "def FilterGD1(stars, gd1_stars):\n",
    "    gd1stars = np.zeros(len(stars))\n",
    "    for x in tqdm(gd1_stars):\n",
    "        ra, dec, pmra, pmdec = x\n",
    "        foundlist = angular_distance(np.dstack((stars[:,3], stars[:,2]))[0], np.array([[ra, dec]]))\n",
    "        foundlist = np.sqrt(foundlist**2 + (stars[:,0] - pmdec)**2 + (stars[:,1] - pmra)**2)\n",
    "        foundlist = foundlist < 0.0001\n",
    "        if len(np.argwhere(foundlist)) == 1:\n",
    "            gd1stars += foundlist\n",
    "    return gd1stars.astype('bool'), stars[gd1stars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19a35d84-7d16-4298-91f3-57b200088903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filename):\n",
    "    column_names = [\"μ_δ\", \"μ_α\", \"δ\", \"α\", \"b-r\", \"g\", \"ϕ\", \"λ\", \"μ_ϕcosλ\", \"μ_λ\"]\n",
    "    gd1_stars = np.load('../gaia_data/gd1/gd1_stars.npy')  # Update path if needed\n",
    "    df = pd.DataFrame(np.load(filename), columns=column_names)\n",
    "\n",
    "    is_stream, stream = FilterGD1(np.array(df), gd1_stars)\n",
    "    df[\"stream\"] = is_stream\n",
    "\n",
    "    df['α_wrapped'] = df['α'].apply(lambda x: x if x > 100 else x + 360)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68237052-029f-446e-9b41-5e2f6deb7e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- More Imports ---\n",
    "from matplotlib import gridspec\n",
    "from scipy import stats\n",
    "from glob import glob\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# --- TensorFlow Keras Imports ---\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import callbacks, regularizers\n",
    "\n",
    "# --- Scikit-learn Imports ---\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02400e07-f2ec-4288-8cd2-5031247ad6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df, layer_size=200, batch_size=10000, dropout=0.2, epochs=100, patience=30,\n",
    "          n_folds=5, best_of_n_loops=3, save_folder=None, other_callbacks=None, verbose=True,\n",
    "          scan_over_mu_phi=False, plot=PLOT):\n",
    "    \n",
    "    df_name = getattr(df, 'name', 'purity')\n",
    "\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    if scan_over_mu_phi:\n",
    "        training_vars = ['ϕ', 'λ', 'μ_λ', 'b-r', 'g']\n",
    "    else:\n",
    "        training_vars = ['ϕ', 'λ', 'μ_ϕcosλ', 'b-r', 'g']\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=15)\n",
    "    fold_stars = []\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(df[training_vars], df.label)):\n",
    "        fold_stars.append(test_index)\n",
    "\n",
    "    fold_labels = np.arange(len(fold_stars))\n",
    "    test_dataframes = []\n",
    "\n",
    "    for fold in fold_labels:\n",
    "        save_folder_fold = os.path.join(save_folder, f\"kfold_{fold}\")\n",
    "        test_stars = fold_stars[fold]\n",
    "\n",
    "        test_scores = []\n",
    "        for val_set in np.delete(fold_labels, fold):\n",
    "            save_folder_val = os.path.join(save_folder_fold, f\"val_set_{val_set}\")\n",
    "            os.makedirs(save_folder_val, exist_ok=True)\n",
    "\n",
    "            val_stars = fold_stars[val_set]\n",
    "            train_stars = np.concatenate([fold_stars[i] for i in np.delete(fold_labels, [fold, val_set])])\n",
    "\n",
    "            train = df.iloc[train_stars]\n",
    "            val = df.iloc[val_stars]\n",
    "            test = df.iloc[test_stars]\n",
    "\n",
    "            sc = preprocessing.StandardScaler()\n",
    "            train_x = sc.fit_transform(train[training_vars])\n",
    "            train_y = train.label.to_numpy()\n",
    "\n",
    "            val_x = sc.transform(val[training_vars])\n",
    "            val_y = val.label.to_numpy()\n",
    "\n",
    "            test_x = sc.transform(test[training_vars])\n",
    "            test_y = test.label.to_numpy()\n",
    "\n",
    "            sample_weight = train.weight.to_numpy() if \"weight\" in train.columns and len(train.weight.unique()) > 1 else None\n",
    "\n",
    "            val_losses = []\n",
    "            for n in range(best_of_n_loops):\n",
    "                loop_folder = os.path.join(save_folder_val, f\"loop_{n}\")\n",
    "                os.makedirs(loop_folder, exist_ok=True)\n",
    "\n",
    "                ### NEW: Build the model inside strategy scope\n",
    "                with strategy.scope():\n",
    "                    model = Sequential([\n",
    "                        Dense(layer_size, input_dim=len(training_vars), activation='relu'),\n",
    "                        Dropout(dropout),\n",
    "                        Dense(layer_size, activation='relu'),\n",
    "                        Dropout(dropout),\n",
    "                        Dense(layer_size, activation='relu'),\n",
    "                        Dropout(dropout),\n",
    "                        Dense(1, activation='sigmoid')\n",
    "                    ])\n",
    "\n",
    "                    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "                early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=patience, verbose=0)\n",
    "                checkpoint = callbacks.ModelCheckpoint(os.path.join(loop_folder, \"weights.h5\"),\n",
    "                                                       monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "                callbacks_list = [checkpoint, early_stopping]\n",
    "                if other_callbacks:\n",
    "                    callbacks_list += other_callbacks\n",
    "\n",
    "                history = model.fit(train_x, train_y,\n",
    "                                    epochs=epochs,\n",
    "                                    sample_weight=sample_weight,\n",
    "                                    batch_size=batch_size,\n",
    "                                    validation_data=(val_x, val_y),\n",
    "                                    callbacks=callbacks_list,\n",
    "                                    verbose=0)\n",
    "\n",
    "                if plot:\n",
    "                    fig, axs = plt.subplots(1, 2, figsize=(12,6))\n",
    "                    axs[0].plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "                    axs[0].plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "                    axs[0].set_title(\"Accuracy\")\n",
    "                    axs[0].set_xlabel(\"Epochs\")\n",
    "                    axs[0].legend()\n",
    "\n",
    "                    axs[1].plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "                    axs[1].plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "                    axs[1].set_title(\"Loss\")\n",
    "                    axs[1].set_xlabel(\"Epochs\")\n",
    "                    axs[1].legend()\n",
    "\n",
    "                    plt.savefig(os.path.join(loop_folder, \"loss_curve.png\"))\n",
    "                    plt.close()\n",
    "\n",
    "                val_losses.append(np.min(history.history[\"val_loss\"]))\n",
    "\n",
    "            model.load_weights(os.path.join(save_folder_val, f\"loop_{np.argmin(val_losses)}\", \"weights.h5\"))\n",
    "            test = test.copy()  # Prevent SettingWithCopyWarning\n",
    "            test[\"nn_score\"] = model.predict(test_x)\n",
    "            test_scores.append(np.array(test.nn_score))\n",
    "\n",
    "            plot_results(test, save_folder=save_folder_val, verbose=verbose, show=False, plot=plot)\n",
    "\n",
    "        test[\"nn_score\"] = np.mean(test_scores, axis=0)\n",
    "        test.to_hdf(os.path.join(save_folder_fold, \"df_test.h5\"), key=\"df\")\n",
    "        test_dataframes.append(test)\n",
    "\n",
    "    test_full = pd.concat(test_dataframes)\n",
    "    test_full.to_hdf(os.path.join(save_folder, \"df_test.h5\"), key=\"df\")\n",
    "    plot_results(test_full, save_folder=os.path.join(save_folder, \"full_test_set\"), plot=plot)\n",
    "\n",
    "    return test_full\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd37065d-bd16-4e43-b258-b7c78229516f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "# Setup matplotlib\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "\n",
    "# Setup GPU memory growth\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for gpu in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Setup multi-GPU strategy\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(f\"Number of devices: {strategy.num_replicas_in_sync}\")\n",
    "\n",
    "# Base directory to save everything\n",
    "base_save_dir = \"/global/cfs/projectdirs/m3246/mgolshan/last_20\"\n",
    "os.makedirs(base_save_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85db5c53-a20f-4192-b9b3-6a033693bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_stream_labels_and_remove(df, stream_percentage):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    if stream_percentage == 0.0:\n",
    "        df_copy = df_copy[df_copy['stream'] == False]\n",
    "    else:\n",
    "        stream_indices = df_copy[df_copy['stream'] == True].index\n",
    "        n_streams_to_keep = int(len(stream_indices) * stream_percentage)\n",
    "        indices_to_keep = np.random.choice(stream_indices, n_streams_to_keep, replace=False)\n",
    "        df_copy = df_copy.drop(index=stream_indices.difference(indices_to_keep))\n",
    "    \n",
    "    input_name = getattr(df, 'name', 'unnamed_df')\n",
    "    df_copy.name = f\"{input_name}_stream_{stream_percentage:.2f}\"\n",
    "    \n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22351a39-bed1-467a-8049-438940a80e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Find the last 20 mock streams ---\n",
    "stream_dir = \"/global/cfs/projectdirs/m3246/mgolshan/mock_streams/\"\n",
    "all_stream_files = sorted(glob(os.path.join(stream_dir, \"*.npy\")))\n",
    "selected_streams = all_stream_files[-20:]  # Last 20 files\n",
    "\n",
    "# Define the desired stream percentages\n",
    "stream_percentages = [0.2,0.4,0.6, 0.8, 1.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6998c927-4889-44c3-abbe-d19c10fec6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "Starting Run 1/3\n",
      "=========================\n",
      "Processing with 20% stream stars...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted DataFrame name: mock_933_stream_0.20\n",
      "SR factor: 0.25\n",
      "SB factor: 0.5\n",
      "Scanning over μ_λ\n",
      "Sideband region: [0.3,0.4) & (0.6,0.7]\n",
      "Signal region: [0.4,0.6]\n",
      "NCCL version 2.16.5+cudaCUDA_MAJOR.CUDA_MINOR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745817359.915418  677202 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n",
      "83/83 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [17:31<5:33:06, 1051.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 Purity: 14.00%\n",
      "Top 100 Purity: 9.00%\n",
      "Adjusted DataFrame name: mock_934_stream_0.20\n",
      "SR factor: 0.25\n",
      "SB factor: 0.5\n",
      "Scanning over μ_λ\n",
      "Sideband region: [1.2,1.7) & (2.5,3.0]\n",
      "Signal region: [1.7,2.5]\n",
      "214/214 [==============================] - 1s 2ms/step\n",
      "214/214 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# Initialize purity logs\n",
    "purity_log_50 = []\n",
    "purity_log_100 = []\n",
    "\n",
    "# Start looping\n",
    "for run in range(1, 4):  # Loop 3 times\n",
    "    print(f\"=========================\")\n",
    "    print(f\"Starting Run {run}/3\")\n",
    "    print(f\"=========================\")\n",
    "\n",
    "    for stream_percentage in stream_percentages:\n",
    "        print(f\"Processing with {int(stream_percentage * 100)}% stream stars...\")\n",
    "\n",
    "        for file in tqdm(selected_streams):\n",
    "            mock_id = file.split('_')[-1][:3]\n",
    "            save_folder = os.path.join(base_save_dir, f\"mock_{mock_id}_{int(stream_percentage * 100)}percent_run{run}\")\n",
    "            os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "            df = pd.DataFrame(\n",
    "                np.load(file),\n",
    "                columns=[\"μ_δ\", \"μ_α\", \"δ\", \"α\", \"b-r\", \"g\", \"ϕ\", \"λ\", \"μ_ϕcosλ\", \"μ_λ\", 'stream']\n",
    "            )\n",
    "            df['α_wrapped'] = df['α'].apply(lambda x: x if x > 100 else x + 360)\n",
    "            df['stream'] = df['stream'] / 100\n",
    "            df['stream'] = df['stream'].astype(bool)\n",
    "            df.name = f\"mock_{mock_id}\"\n",
    "\n",
    "            df_adjusted = adjust_stream_labels_and_remove(df, stream_percentage)\n",
    "            print(f\"Adjusted DataFrame name: {df_adjusted.name}\")\n",
    "\n",
    "            df_slice = signal_sideband(df_adjusted, save_folder=save_folder, sr_factor=0.25, sb_factor=0.5)\n",
    "\n",
    "            tf.keras.backend.clear_session()\n",
    "            test = train(df_slice, verbose=False, save_folder=save_folder, plot=False)\n",
    "\n",
    "            # --- Calculate purity for Top 50 ---\n",
    "            top_n_50 = 50\n",
    "            top_stars_50 = test.sort_values('nn_score', ascending=False).head(top_n_50)\n",
    "            n_stream_stars_50 = top_stars_50.stream.value_counts().get(True, 0) if \"stream\" in top_stars_50.columns else 0\n",
    "            purity_50 = 100 * n_stream_stars_50 / len(top_stars_50) if len(top_stars_50) > 0 else 0\n",
    "            \n",
    "            new_entry_50 = {\n",
    "                \"run\": run,\n",
    "                \"stream_percentage\": stream_percentage,\n",
    "                \"mock_id\": mock_id,\n",
    "                \"top_n\": 50,\n",
    "                \"purity\": purity_50\n",
    "            }\n",
    "            purity_log_50.append(new_entry_50)\n",
    "            \n",
    "            # Append only one row to Top 50 CSV\n",
    "            csv_file_50 = \"purity_results_top50.csv\"\n",
    "            file_exists = os.path.isfile(csv_file_50)\n",
    "            \n",
    "            with open(csv_file_50, 'a', newline='') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=new_entry_50.keys())\n",
    "                if not file_exists:\n",
    "                    writer.writeheader()  # Write header only once if file doesn't exist\n",
    "                writer.writerow(new_entry_50)\n",
    "            \n",
    "            print(f\"Top 50 Purity: {purity_50:.2f}%\")\n",
    "            \n",
    "            # --- Calculate purity for Top 100 ---\n",
    "            top_n_100 = 100\n",
    "            top_stars_100 = test.sort_values('nn_score', ascending=False).head(top_n_100)\n",
    "            n_stream_stars_100 = top_stars_100.stream.value_counts().get(True, 0) if \"stream\" in top_stars_100.columns else 0\n",
    "            purity_100 = 100 * n_stream_stars_100 / len(top_stars_100) if len(top_stars_100) > 0 else 0\n",
    "            \n",
    "            new_entry_100 = {\n",
    "                \"run\": run,\n",
    "                \"stream_percentage\": stream_percentage,\n",
    "                \"mock_id\": mock_id,\n",
    "                \"top_n\": 100,\n",
    "                \"purity\": purity_100\n",
    "            }\n",
    "            purity_log_100.append(new_entry_100)\n",
    "            \n",
    "            # Append only one row to Top 100 CSV\n",
    "            csv_file_100 = \"purity_results_top100.csv\"\n",
    "            file_exists = os.path.isfile(csv_file_100)\n",
    "            \n",
    "            with open(csv_file_100, 'a', newline='') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=new_entry_100.keys())\n",
    "                if not file_exists:\n",
    "                    writer.writeheader()\n",
    "                writer.writerow(new_entry_100)\n",
    "            \n",
    "            print(f\"Top 100 Purity: {purity_100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e673056a-0121-4675-a95f-83bff651acb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cwola)",
   "language": "python",
   "name": "cwola"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
